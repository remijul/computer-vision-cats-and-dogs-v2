# ğŸ±ğŸ¶ Computer Vision Cats & Dogs - V2 Monitoring

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org)
[![FAST Api](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=for-the-badge&logo=Keras&logoColor=white)](https://keras.io/)
[![PostgreSQL](https://img.shields.io/badge/postgresql-4169e1?style=for-the-badge&logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![Pytest](https://img.shields.io/badge/Pytest--cov-%233F51B5?style=for-the-badge&logo=pytest&logoColor=white&labelColor=black)](https://docs.pytest.org/en/stable/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](LICENSE)

<div align="center">

<h3>Classification d'images avec Keras et exposition du modÃ¨le via Fast API</br></h3>
<h3>Version enrichie avec monitoring et feedback utilisateur</br></h3>

[Explore the docs](docs/)

</div>

---

## ğŸ“Œ Introduction

Il s'agit de la version 2 du projet, dans une sÃ©rie de 3 versions, la version 2 a pour objectif de dÃ©velopper une solution de monitoring (incluant le "human feedback loop") et la version 3 de proposer une solution ML Ops avancÃ©e (monitoring avancÃ©, tests automatisÃ©s et dÃ©ploiement continu).

## ğŸ” Vue d'ensemble

Cette version 2 Ã©tend le projet de classification d'images en ajoutant des fonctionnalitÃ©s de monitoring avancÃ©es, une collecte de feedback utilisateur conforme RGPD, et un dashboard de surveillance en temps rÃ©el.

### âœ¨ Nouvelles fonctionnalitÃ©s V2

- **Base de donnÃ©es PostgreSQL** : Stockage persistant des prÃ©dictions et mÃ©triques
- **Collecte de feedback utilisateur** : SystÃ¨me de satisfaction avec respect du RGPD
- **Dashboard de monitoring** : Visualisations interactives avec Plotly
- **Tests automatisÃ©s Ã©tendus** : Tests de base de donnÃ©es et API
- **Pipeline CI/CD complet** : Tests automatiques sur GitHub Actions

## ğŸ—ï¸ Architecture de l'application

### ğŸ› ï¸ Stack technologique

- **IA** : Keras 3 + TensorFlow (CNN)
- **API** : FastAPI avec authentification par token
- **Base de donnÃ©es** : PostgreSQL avec SQLAlchemy
- **Frontend** : Templates Jinja2 + Bootstrap 5 + Bootstrap Icons
- **Visualisation** : Plotly pour les graphiques interactifs
- **Tests** : pytest avec PostgreSQL de test
- **CI/CD** : GitHub Actions

### ğŸ”„ Architecture fonctionelle

```mermaid
graph TB
    subgraph "Data Layer"
        A[ğŸ“ Raw Data<br/>data/raw/] --> B[ğŸ“ Processed Data<br/>data/processed/]
        C[ğŸ“ External Data<br/>data/external/]
        DB[(ğŸ—„ï¸ PostgreSQL<br/>predictions_feedback<br/>Monitoring Data)]
    end
    
    subgraph "ML Pipeline"
        D[ğŸ§  CNN Model<br/>Keras 3<br/>src/models/] 
        E[ğŸ“Š Data Processing<br/>src/data/]
        F[ğŸ“ˆ Monitoring Service<br/>src/monitoring/<br/>Dashboard & KPIs]
    end
    
    subgraph "Database Layer"
        DBConn[ğŸ”— DB Connector<br/>src/database/db_connector.py]
        DBModels[ğŸ“‹ SQLAlchemy Models<br/>src/database/models.py]
        DBService[âš™ï¸ Feedback Service<br/>src/database/feedback_service.py]
    end
    
    subgraph "Application Layer"
        G[ğŸš€ FastAPI Server<br/>src/api/main.py]
        H[ğŸŒ Web Interface<br/>src/web/<br/>Jinja2 Templates]
        I[ğŸ”§ Utils<br/>src/utils/]
        R[ğŸ¯ Prediction Endpoint<br/>/api/predict<br/>+ RGPD Consent]
        MON[ğŸ“Š Monitoring Dashboard<br/>/monitoring<br/>Plotly Charts]
    end
    
    subgraph "DevOps & Infrastructure"
        K[âš™ï¸ CI/CD<br/>.github/workflows/<br/>PostgreSQL Service]
        L[ğŸ“‹ Scripts<br/>scripts/]
        M[ğŸ§ª Extended Tests<br/>tests/<br/>API + Database]
    end
    
    subgraph "Configuration & Documentation"
        N[âš™ï¸ Config<br/>config/<br/>DB Settings]
        O[ğŸ“š Documentation<br/>docs/]
        Q[ğŸ“¦ Requirements<br/>requirements/]    
    end
    
    %% Data Flow V2
    B --> E
    E --> D
    D --> G
    G --> H
    G --> R
    G --> MON
    
    %% Database Integration
    R --> DBService
    DBService --> DB
    DBConn --> DB
    DBModels --> DBService
    F --> DB
    MON --> F
    
    %% Enhanced DevOps
    M --> K
    M --> DB
    L --> G
    
    %% Configuration
    N --> G
    N --> D
    N --> DBConn
    Q --> G
    Q --> D
    
    %% Documentation & Development
    O --> H
    
    %% Styling
    classDef dataClass fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef mlClass fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef appClass fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    classDef devopsClass fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef configClass fill:#fafafa,stroke:#424242,stroke-width:2px
    classDef dbClass fill:#ffebee,stroke:#c62828,stroke-width:2px
    
    class A,B,C,DB dataClass
    class D,E,F mlClass
    class G,H,I,R,MON appClass
    class K,L,M devopsClass
    class N,O,Q configClass
    class DBConn,DBModels,DBService dbClass
```

### ğŸ“ Structure du projet

```txt
project-name/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ workflows/           # CI/CD pipelines
â”‚   â””â”€â”€ ISSUE_TEMPLATE/      # Templates d'issues
â”œâ”€â”€ config/                  # Fichiers de configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # DonnÃ©es brutes (gitignored)
â”‚   â”œâ”€â”€ processed/           # DonnÃ©es traitÃ©es (gitignored)
â”‚   â””â”€â”€ external/            # DonnÃ©es externes/rÃ©fÃ©rences
â”œâ”€â”€ docker/                  # Dockerfiles et compose
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ notebooks/               # Jupyter notebooks pour exploration
â”œâ”€â”€ requirements/            # DÃ©pendances par environnement
â”‚   â”œâ”€â”€ base.txt
â”‚   â”œâ”€â”€ dev.txt
â”‚   â””â”€â”€ prod.txt
â”œâ”€â”€ scripts/                 # Scripts d'automatisation/dÃ©ploiement
â”œâ”€â”€ src/                     # Code source principal
â”‚   â”œâ”€â”€ api/                 # APIs et services web
â”‚   â”œâ”€â”€ data/                # Scripts de traitement des donnÃ©es
â”‚   â”œâ”€â”€ database/            # Gestion base de donnÃ©es
â”‚       â”œâ”€â”€ db_connector.py    # Connexion PostgreSQL
â”‚       â”œâ”€â”€ models.py          # ModÃ¨les SQLAlchemy
â”‚       â”œâ”€â”€ schemas.py         # SchÃ©mas Pydantic
â”‚       â”œâ”€â”€ feedback_service.py# Service mÃ©tier
â”‚       â”œâ”€â”€ db_creator.py      # Script crÃ©ation DB
â”‚       â””â”€â”€ table_creator.py   # Script crÃ©ation tables
â”‚   â”œâ”€â”€ models/              # ModÃ¨les ML/IA
â”‚   â”œâ”€â”€ monitoring/          # Monitoring des modÃ¨les et de l'application
â”‚       â””â”€â”€ dashboard_service.py# GÃ©nÃ©ration graphiques
â”‚   â”œâ”€â”€ utils/               # Utilitaires partagÃ©s
â”‚   â””â”€â”€ web/                 # Templates jinja2
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ base.html        # Template de base
â”‚       â”œâ”€â”€ inference.html   # Page de prÃ©diction
â”‚       â””â”€â”€ monitoring.html  # Dashboard monitoring
â”œâ”€â”€ tests/                   # Tests unitaires et d'intÃ©gration
â”‚   â”œâ”€â”€ test_api_simple.py   # Tests API
â”‚   â””â”€â”€ test_db_simple.py    # Tests base de donnÃ©es
â”œâ”€â”€ .env                     # Variables d'environnement (Ã  configurer)
â”œâ”€â”€ .env.example             # Variables d'environnement exemple
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ Makefile                 # Commandes frÃ©quentes
â””â”€â”€ pyproject.toml           # Configuration Python/packaging
```

## âš™ï¸ FonctionnalitÃ©s dÃ©taillÃ©es

### ğŸ“Š Monitoring et analytics

#### KPI temps d'infÃ©rence

- Temps moyen, minimum, maximum
- Courbe temporelle d'Ã©volution
- Nombre total de prÃ©dictions

#### KPI satisfaction utilisateur

- Taux de satisfaction en pourcentage
- RÃ©partition satisfait/insatisfait
- Scatter plot temporel des feedbacks

### ğŸ›¡ï¸ ConformitÃ© RGPD

- Consentement explicite de l'utilisateur
- Stockage conditionnel des donnÃ©es personnelles
- MÃ©triques anonymes par dÃ©faut
- Pas de stockage du nom de fichier sans consentement

### ğŸ—„ï¸ Base de donnÃ©es

#### Table `predictions_feedback`

- id, timestamp, created_at : Identifiants et horodatage
- inference_time_ms, success : MÃ©triques de performance
- prediction_result, proba_cat, proba_dog : RÃ©sultats de prÃ©diction
- rgpd_consent, filename : DonnÃ©es RGPD
- user_feedback, user_comment : Feedback utilisateur

## ğŸš€ Installation et utilisation

### ğŸ“‹ PrÃ©requis

- Python 3.11+
- PostgreSQL 15+
- Git

### âš¡ Installation

- Cloner le repository
- CrÃ©er l'environnement virtuel
- Installer les dÃ©pendances via `requirements/base.txt`

### âš™ï¸ Configuration

- CrÃ©er un fichier `.env` Ã  la racine avec la configuration PostgreSQL (DB_HOST, DB_PORT, DB_NAME, DB_USER, DB_PWD, DB_TABLE_MONITORING) et le token API.
- Voir le fichier `.env.example` pour exemple.

### ğŸ—ƒï¸ Initialisation de la base de donnÃ©es

- ExÃ©cuter successivement : `db_connector.py` pour tester la connexion, puis  `db_creator.py` pour crÃ©er la base, et enfin `table_creator.py` pour crÃ©er la table de monitoring.

### ğŸš€ Lancement de l'application

DÃ©marrer l'API avec `scripts/run_api.py` puis accÃ©der Ã  :

- http://127.0.0.1:8000 : Interface principale
- http://127.0.0.1:8000/docs : Documentation API
- http://127.0.0.1:8000/monitoring : Dashboard monitoring

- Page de documentation de l'API (Swagger) :

![Swagger](/docs/img/swagger.png "Page de documentation de l'API")

- Page d'accueil de l'application :

![Web APP](/docs/img/web.png "Application web du projet")

## ğŸ§ª Tests

### ğŸ”§ Tests manuels

- ExÃ©cuter `tests/test_db_simple.py` pour les tests base de donnÃ©es
- ExÃ©cuter `tests/test_api_simple.py` pour les tests API.

### ğŸ¤– Tests automatisÃ©s (CI/CD)

Le pipeline GitHub Actions exÃ©cute automatiquement les tests de connexion PostgreSQL, la vÃ©rification de la structure des tables, et les tests de l'API avec modÃ¨le factice.

## ğŸ”Œ API Endpoints

### ğŸ¯ PrÃ©diction

- POST `/api/predict` : Classification d'image avec collecte de feedback
- POST `/api/update-feedback` : Mise Ã  jour du feedback utilisateur

### ğŸ“ˆ Monitoring

- GET `/api/statistics` : Statistiques globales
- GET `/api/recent-predictions` : DerniÃ¨res prÃ©dictions
- GET `/monitoring` : Dashboard web interactif

### âš¡ SystÃ¨me

- GET `/health` : Ã‰tat de l'API et de la base de donnÃ©es
- GET `/api/info` : Informations sur le modÃ¨le

## ğŸ“ˆ Ã‰volutions par rapport Ã  la V1

```markdown
| FonctionnalitÃ©  | V1              | V2                        |
|-----------------|-----------------|---------------------------|
| **Stockage**    | Fichiers CSV    | PostgreSQL                |
| **Monitoring**  | Logs basiques   | Dashboard interactif      |
| **Feedback**    | Aucun           | Collecte utilisateur RGPD |
| **Visualisation** | Aucune        | Graphiques Plotly         |
| **Tests**       | API uniquement  | API + Base de donnÃ©es     |
| **CI/CD**       | Basique         | Pipeline complet          |
```

## ğŸ’» DÃ©veloppement

### ğŸ›ï¸ Architecture des donnÃ©es

Le systÃ¨me collecte et analyse les temps d'infÃ©rence pour optimisation des performances, la prÃ©cision des prÃ©dictions pour amÃ©lioration du modÃ¨le, la satisfaction utilisateur pour amÃ©lioration de l'expÃ©rience, et les commentaires utilisateur pour insights qualitatifs.

### ğŸ”® xtensibilitÃ©

La V2 prÃ©pare les Ã©volutions vers la V3 MLOps avec une infrastructure de donnÃ©es Ã©tablie, des mÃ©triques standardisÃ©es, un pipeline de tests robuste, et un monitoring des performances en place.

## ğŸ“„ Licence

MIT - Projet Ã©ducatif Ã  des fins pÃ©dagogiques

## ğŸ¤ Contributions

Ce projet est utilisÃ© dans un cadre pÃ©dagogique. Les contributions sont bienvenues pour amÃ©liorer l'expÃ©rience d'apprentissage.

---

**Version** : 2.0.0  
**Status** : Production ready pour dÃ©monstration  
**Next** : V3 avec MLOps avancÃ©  
